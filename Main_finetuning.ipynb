{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "31a882d8-e19a-48b3-a68b-2e682537e3c5",
   "metadata": {},
   "source": [
    "### Load and Prepare Data(Sephora Reviews)\n",
    "- This is the same dataset I used in my assignment part1 & part2; \n",
    "- loading, preprocessing, and evaluating a base model before fine-tuning."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "11819a87-be17-4366-82cc-6b988ae95391",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import kagglehub\n",
    "import json\n",
    "from transformers import AutoTokenizer, AutoModelForSeq2SeqLM, pipeline\n",
    "import os\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "64bac4e0-113a-4e62-923e-68b3615d175d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Warning: Looks like you're using an outdated `kagglehub` version (installed: 0.3.9), please consider upgrading to the latest version (0.3.10).\n",
      "Path to dataset files: /nfs/home/vlr3588/.cache/kagglehub/datasets/nadyinky/sephora-products-and-skincare-reviews/versions/2\n"
     ]
    }
   ],
   "source": [
    "# Downloading from the Kaggle \n",
    "path = kagglehub.dataset_download(\"nadyinky/sephora-products-and-skincare-reviews\")\n",
    "print(\"Path to dataset files:\", path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "6754cf25-1812-42f5-bc11-17bcb548d0fa",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_3517348/2589632883.py:11: DtypeWarning: Columns (1) have mixed types. Specify dtype option on import or set low_memory=False.\n",
      "  review_dfs = [pd.read_csv(os.path.join(dataset_dir, file)) for file in review_files] # Loading and combine all review files into one DataFrame\n",
      "/tmp/ipykernel_3517348/2589632883.py:11: DtypeWarning: Columns (1) have mixed types. Specify dtype option on import or set low_memory=False.\n",
      "  review_dfs = [pd.read_csv(os.path.join(dataset_dir, file)) for file in review_files] # Loading and combine all review files into one DataFrame\n",
      "/tmp/ipykernel_3517348/2589632883.py:11: DtypeWarning: Columns (1) have mixed types. Specify dtype option on import or set low_memory=False.\n",
      "  review_dfs = [pd.read_csv(os.path.join(dataset_dir, file)) for file in review_files] # Loading and combine all review files into one DataFrame\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total reviews loaded: 1094411\n"
     ]
    }
   ],
   "source": [
    "# Getting all the datasets from the Kaggle\n",
    "dataset_dir = path \n",
    "review_files = [\n",
    "    \"reviews_0-250.csv\",\n",
    "    \"reviews_250-500.csv\",\n",
    "    \"reviews_500-750.csv\",\n",
    "    \"reviews_750-1250.csv\",\n",
    "    \"reviews_1250-end.csv\"\n",
    "]\n",
    "\n",
    "review_dfs = [pd.read_csv(os.path.join(dataset_dir, file)) for file in review_files] # Loading and combine all review files into one DataFrame\n",
    "reviews = pd.concat(review_dfs, ignore_index=True)\n",
    "\n",
    "print(\"Total reviews loaded:\", len(reviews))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "0a5d82fd-8aa9-43d0-a67c-2142b11bdb3b",
   "metadata": {},
   "outputs": [],
   "source": [
    "#data = reviews\n",
    "#data = data.drop(columns=['Unnamed: 0'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "cd6a6252-c54a-47a7-8cc0-5d32bf7a0596",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Filtered reviews (2023): 49531\n",
      "   Unnamed: 0    author_id  rating  is_recommended  helpfulness  \\\n",
      "0           0   1741593524       5             1.0          1.0   \n",
      "1           1  31423088263       1             0.0          NaN   \n",
      "2           2   5061282401       5             1.0          NaN   \n",
      "3           3   6083038851       5             1.0          NaN   \n",
      "4           4  47056667835       5             1.0          NaN   \n",
      "\n",
      "   total_feedback_count  total_neg_feedback_count  total_pos_feedback_count  \\\n",
      "0                     2                         0                         2   \n",
      "1                     0                         0                         0   \n",
      "2                     0                         0                         0   \n",
      "3                     0                         0                         0   \n",
      "4                     0                         0                         0   \n",
      "\n",
      "  submission_time                                        review_text  \\\n",
      "0      2023-02-01  I use this with the Nudestix “Citrus Clean Bal...   \n",
      "1      2023-03-21  I bought this lip mask after reading the revie...   \n",
      "2      2023-03-21  My review title says it all! I get so excited ...   \n",
      "3      2023-03-20  I’ve always loved this formula for a long time...   \n",
      "4      2023-03-20  If you have dry cracked lips, this is a must h...   \n",
      "\n",
      "                       review_title skin_tone eye_color    skin_type  \\\n",
      "0  Taught me how to double cleanse!       NaN     brown          dry   \n",
      "1                      Disappointed       NaN       NaN          NaN   \n",
      "2              New Favorite Routine     light     brown          dry   \n",
      "3   Can't go wrong with any of them       NaN     brown  combination   \n",
      "4                   A must have !!!     light     hazel  combination   \n",
      "\n",
      "  hair_color product_id                                       product_name  \\\n",
      "0      black    P504322                     Gentle Hydra-Gel Face Cleanser   \n",
      "1        NaN    P420652  Lip Sleeping Mask Intense Hydration with Vitam...   \n",
      "2     blonde    P420652  Lip Sleeping Mask Intense Hydration with Vitam...   \n",
      "3      black    P420652  Lip Sleeping Mask Intense Hydration with Vitam...   \n",
      "4        NaN    P420652  Lip Sleeping Mask Intense Hydration with Vitam...   \n",
      "\n",
      "  brand_name  price_usd  \n",
      "0   NUDESTIX       19.0  \n",
      "1    LANEIGE       24.0  \n",
      "2    LANEIGE       24.0  \n",
      "3    LANEIGE       24.0  \n",
      "4    LANEIGE       24.0  \n",
      "Filtered reviews saved to 'Sephora_skincare_Reviews_2023.csv'\n"
     ]
    }
   ],
   "source": [
    "# Filtering Reviews After 2023\n",
    "reviews['submission_time'] = pd.to_datetime(reviews['submission_time'])\n",
    "\n",
    "# Filter reviews for the year 2023\n",
    "filtered_reviews_2023 = reviews[(reviews['submission_time'].dt.year == 2023)]\n",
    "\n",
    "print(\"Filtered reviews (2023):\", len(filtered_reviews_2023))\n",
    "print(filtered_reviews_2023.head()) \n",
    "\n",
    "# Save filtered reviews to a CSV file\n",
    "filtered_reviews_2023.to_csv(\"Sephora_skincare_Reviews_2023.csv\", index=False)\n",
    "print(\"Filtered reviews saved to 'Sephora_skincare_Reviews_2023.csv'\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "567ac6bf-11a2-4170-a023-46ebec85432d",
   "metadata": {},
   "outputs": [],
   "source": [
    "data = pd.read_csv('Sephora_skincare_Reviews_2023.csv')\n",
    "data = data.drop(columns=['Unnamed: 0'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "f4cd3fa7-3ec4-490e-84ed-bd754d4b5076",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(49531, 19)"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "filtered_reviews_2023.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "a57338d4-b450-4604-92c3-ee3d04212770",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Columns in the dataset: Index(['author_id', 'rating', 'is_recommended', 'helpfulness',\n",
      "       'total_feedback_count', 'total_neg_feedback_count',\n",
      "       'total_pos_feedback_count', 'submission_time', 'review_text',\n",
      "       'review_title', 'skin_tone', 'eye_color', 'skin_type', 'hair_color',\n",
      "       'product_id', 'product_name', 'brand_name', 'price_usd'],\n",
      "      dtype='object')\n"
     ]
    }
   ],
   "source": [
    "# Display column names\n",
    "print(\"Columns in the dataset:\", data.columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "16836563-d751-4e16-91a0-5566d94aebd3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                                         review_text  rating\n",
      "0  I use this with the Nudestix “Citrus Clean Bal...       5\n",
      "1  I bought this lip mask after reading the revie...       1\n",
      "2  My review title says it all! I get so excited ...       5\n",
      "3  I’ve always loved this formula for a long time...       5\n",
      "4  If you have dry cracked lips, this is a must h...       5\n"
     ]
    }
   ],
   "source": [
    "print(data[['review_text', 'rating']].head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "3775b271-a6e1-4e4a-93b6-b4ceea007ea8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Cleaned dataset size: 49507\n"
     ]
    }
   ],
   "source": [
    "# Keep only review text and rating\n",
    "data = data[['review_text', 'rating']]\n",
    "\n",
    "# Drop missing values\n",
    "data.dropna(inplace=True)\n",
    "\n",
    "print(\"Cleaned dataset size:\", len(data))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "970bb807-63d1-4858-a099-4944745f0253",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Select GPU (adjust as per your cluster)\n",
    "os.environ[\"CUDA_VISIBLE_DEVICES\"] = \"0\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "2de22efb-14f7-4377-9857-7ff7b8de1d76",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "sentiment\n",
      "Positive    40474\n",
      "Negative     5492\n",
      "Neutral      3541\n",
      "Name: count, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "# Define a function to map ratings to sentiment labels\n",
    "def map_rating_to_sentiment(rating):\n",
    "    if rating >= 4:\n",
    "        return \"Positive\"\n",
    "    elif rating == 3:\n",
    "        return \"Neutral\"\n",
    "    else:\n",
    "        return \"Negative\"\n",
    "\n",
    "# Apply function to create a new sentiment column\n",
    "data['sentiment'] = data['rating'].apply(map_rating_to_sentiment)\n",
    "\n",
    "# Drop rating column\n",
    "data = data.drop(columns=['rating'])\n",
    "\n",
    "# Show sentiment distribution\n",
    "print(data['sentiment'].value_counts())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "189ffb10-7d44-4a4e-83b6-e9fe0d32406d",
   "metadata": {},
   "source": [
    "### Converting Data into Question-Answer Format"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "0441a696-e3b8-46fb-b1ad-99715183614f",
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_qa_pair(row):\n",
    "    question = f\"What is the sentiment of this review? '{row['review_text']}'\"\n",
    "    answer = row['sentiment']\n",
    "    return {'question': question, 'answer': answer}\n",
    "\n",
    "qa_data = data.apply(create_qa_pair, axis=1).tolist()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "b8828fd5-f1d1-47e7-aa8a-4b2cf7ab3d3a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save the full dataset\n",
    "with open(\"sentiment_dataset.json\", \"w\") as f:\n",
    "    json.dump(qa_data, f, indent=4)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c72aff01-80c9-4326-95be-560bff837389",
   "metadata": {},
   "source": [
    "## Test the base model on the test questions\n",
    "- Selecting a small language model (≤1.7B parameters)\n",
    "- flan-t5-small is a general-purpose instruction-tuned model and has not been specifically trained on Sephora product reviews or this particular type of sentiment task.\n",
    "- Neutral sentiment is often the hardest class to detect in sentiment analysis, especially for general-purpose LLMs."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "a66ae694-f972-4d95-aea5-5c807bb9379a",
   "metadata": {},
   "outputs": [],
   "source": [
    "#!pip install torch transformers datasets\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "d20a46e1-f334-4f2f-ae82-8e83db0ad845",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Select first 15 questions from the dataset\n",
    "test_questions = qa_data[:15]\n",
    "\n",
    "# Save the test questions\n",
    "with open(\"test_questions.json\", \"w\") as f:\n",
    "    json.dump(test_questions, f, indent=4)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "7ba2c93b-9984-4613-a5fd-d880a370988f",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/nfs/home/vlr3588/.local/lib/python3.9/site-packages/huggingface_hub/file_download.py:797: FutureWarning: `resume_download` is deprecated and will be removed in version 1.0.0. Downloads always resume when possible. If you want to force a new download, use `force_download=True`.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Question: What is the sentiment of this review? 'I use this with the Nudestix “Citrus Clean Balm & Make-Up Melt“ to double cleanse and it has completely changed my skin (for the better). The make-up melt is oil based and removes all of your makeup super easily. I follow-up with this water based cleanser, and I also use this just by itself when I’m not wearing make-up. It leaves the skin gently cleansed, but without stripping the skin. 10/10 recommend combining with the make-up melt. It’s perfection!'\n",
      "True Sentiment: Positive\n",
      "Base Model Answer: this review.! this review\n",
      "\n",
      "Question: What is the sentiment of this review? 'I bought this lip mask after reading the reviews and the hype. Unfortunately, it did not meet my expectations as vaseline petroleum jelly works way better for me.'\n",
      "True Sentiment: Negative\n",
      "Base Model Answer: this review??? What\n",
      "\n",
      "Question: What is the sentiment of this review? 'My review title says it all! I get so excited to get into bed and apply this lip mask. I do see a difference because I suffer from dry cracked lips. I drink a lot of water and apply lip balm daily but nothing helped until I started using this. untiluntistafted usinf this.'\n",
      "True Sentiment: Positive\n",
      "Base Model Answer: this review?? this review\n",
      "\n",
      "Question: What is the sentiment of this review? 'I’ve always loved this formula for a long time. I honestly don’t even use it for night time. I use it as an everyday lip balm. I love the texture. Gummy Bear is my second most favourite scent. Grapefruit is the best in my opinion.'\n",
      "True Sentiment: Positive\n",
      "Base Model Answer: this review?? this formula\n",
      "\n",
      "Question: What is the sentiment of this review? 'If you have dry cracked lips, this is a must have. After a few weeks of use I have learned I will always have by my bedside. I thought it was a little expensive but a little goes a long way. It is worth the price.'\n",
      "True Sentiment: Positive\n",
      "Base Model Answer: this review?? a\n",
      "\n",
      "Question: What is the sentiment of this review? 'The scent isn’t my favourite but it works great! I put it on every night before I go to sleep and every morning I wake up with smooth, moisturizer and soft. Packaging is amazing as well'\n",
      "True Sentiment: Positive\n",
      "Base Model Answer: ????\n",
      "\n",
      "Question: What is the sentiment of this review? 'I’ll give this 2 stars for nice packaging and lovely scent. Upon initial application, it feels very nice. But as I continued to use it I noticed I was getting more and more blackheads/clogged pores and pimples around my lips. I thought it was my Aquaphor but it’s THIS!!!! It also makes my lips even more dry than they initially were. Disappointing:( around my'\n",
      "True Sentiment: Negative\n",
      "Base Model Answer: this review? this review?\n",
      "\n",
      "Question: What is the sentiment of this review? 'I use this at night or while I’m putting makeup on. Love the way I don’t have to reapply it during the night. Definitely a win.'\n",
      "True Sentiment: Positive\n",
      "Base Model Answer: this review?? the way\n",
      "\n",
      "Question: What is the sentiment of this review? 'I love this stuff. I first had the sample size from a Sephora Birthday gift, and once I had run through it I knew it was a purchase. I live in an incredibly dry environment, great for macarons, but terrible for my skin. This lip mask helps to keep my lips from becoming too chapped.'\n",
      "True Sentiment: Positive\n",
      "Base Model Answer: this review? of this review?\n",
      "\n",
      "Question: What is the sentiment of this review? 'I purchased the Sweet Candy scent at my local Sephora and I am OBSESSED!! I will be honest, the scent is a bit strong - but they’re all strongly scented. My lips are so soft. 10/10!'\n",
      "True Sentiment: Positive\n",
      "Base Model Answer: this review?? this review\n",
      "\n",
      "Question: What is the sentiment of this review? 'this product is a bit pricey but after using one scoop i figured this will take a LONG time to use up the whole container. it smells so good and the container is so cute.'\n",
      "True Sentiment: Positive\n",
      "Base Model Answer: this review?? the review\n",
      "\n",
      "Question: What is the sentiment of this review? 'I use this every night and morning and it works wonders! This never fails to make my lips super hydrated! The tint and shine to it makes it even a great lip gloss during the day!'\n",
      "True Sentiment: Positive\n",
      "Base Model Answer: this review?? this review\n",
      "\n",
      "Question: What is the sentiment of this review? 'A little goes a long way. Love the fragrance and works great as a night lip mask. Only reason I gave it 4 stars is because of the price.'\n",
      "True Sentiment: Positive\n",
      "Base Model Answer: this review?? this review\n",
      "\n",
      "Question: What is the sentiment of this review? 'Honestly I was so excited when I got this in the mail. But unfortunately it is not worth the hype :( I have boughten two of these full size and I went through them so quickly. The ingredients are not very clean and this product made my lips so dry. I wanted to like this product so bad as it’s so cute and smells nice. But unfortunately it is a hard pass for me. I will be sticking to my vaseline and aquaphor for now :/'\n",
      "True Sentiment: Negative\n",
      "Base Model Answer: I was so excited when I got this\n",
      "\n",
      "Question: What is the sentiment of this review? 'Does the gummy bear mask smell absolutely delicious?! Yes. Does it do much for my lips overnight? Nope. They are dry and a little chapped in the morning. I honestly have better luck with my vaseline lip therapy but I am still keeping the Laneige to use as a daily balm.'\n",
      "True Sentiment: Neutral\n",
      "Base Model Answer: this review?? the Lane\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Load test questions\n",
    "with open(\"test_questions.json\", \"r\") as f:\n",
    "    test_questions = json.load(f)\n",
    "\n",
    "# Load base model and tokenizer\n",
    "model_name = \"t5-small\"\n",
    "tokenizer = AutoTokenizer.from_pretrained(model_name)\n",
    "model = AutoModelForSeq2SeqLM.from_pretrained(model_name)\n",
    "\n",
    "# Build the pipeline\n",
    "qa_pipeline = pipeline(\"text2text-generation\", model=model, tokenizer=tokenizer)\n",
    "\n",
    "# Evaluate the base model on the test set\n",
    "for sample in test_questions:\n",
    "    question = sample[\"question\"]\n",
    "    true_answer = sample[\"answer\"]\n",
    "\n",
    "    response = qa_pipeline(question, max_length=10)[0]['generated_text']\n",
    "\n",
    "    print(f\"Question: {question}\")\n",
    "    print(f\"True Sentiment: {true_answer}\")\n",
    "    print(f\"Base Model Answer: {response}\\n\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "372fa19b-2661-46d3-a800-f2554f0ee212",
   "metadata": {},
   "source": [
    "### Conclusion from the above model :\n",
    "- My base t5-small model (without any fine-tuning) is not able to perform the sentiment classification task effectively.\n",
    "- The base t5-small model is not trained on the sentiment classification task."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ead6380e-1271-46f1-8b27-3adf5f5099a9",
   "metadata": {},
   "source": [
    "## LoRA Fine-tuning with PEFT"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "7f6bb231-e543-4d02-9522-4d1ae3c5e7ed",
   "metadata": {},
   "outputs": [],
   "source": [
    "#import os\n",
    "#os.environ[\"CUDA_VISIBLE_DEVICES\"] = \"0\"\n",
    "#device = \"cuda\"\n",
    "#import os\n",
    "#os.environ[\"CUDA_VISIBLE_DEVICES\"] = \"4\"\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "3d82c524-3481-4329-aced-8a4e32af4987",
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(\"sentiment_dataset.json\", \"r\") as f:\n",
    "    train_data = json.load(f)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ee9ecbe1-0b88-49c4-a869-d45d82c0287d",
   "metadata": {},
   "source": [
    "### Tokenize the dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "6cafd5f4-7a50-4dbd-8e54-d8c81ff81cb2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "27cec473e0d047c299fa9cc8000ff22a",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/49507 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from datasets import Dataset\n",
    "from transformers import AutoTokenizer\n",
    "\n",
    "# Load dataset\n",
    "train_dataset = Dataset.from_list(train_data)\n",
    "\n",
    "# Tokenizer\n",
    "tokenizer = AutoTokenizer.from_pretrained(\"t5-small\")\n",
    "\n",
    "# Tokenization function\n",
    "def tokenize_function(example):\n",
    "    model_inputs = tokenizer(\n",
    "        example[\"question\"],\n",
    "        max_length=256,\n",
    "        padding=\"max_length\",\n",
    "        truncation=True,\n",
    "    )\n",
    "    labels = tokenizer(\n",
    "        example[\"answer\"],\n",
    "        max_length=5,\n",
    "        padding=\"max_length\",\n",
    "        truncation=True,\n",
    "    )\n",
    "    labels[\"input_ids\"] = [\n",
    "        (token if token != tokenizer.pad_token_id else -100)\n",
    "        for token in labels[\"input_ids\"]\n",
    "    ]\n",
    "    model_inputs[\"labels\"] = labels[\"input_ids\"]\n",
    "    return model_inputs\n",
    "\n",
    "# Apply tokenization\n",
    "tokenized_dataset = train_dataset.map(tokenize_function, batched=False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "5f157d1b-6a09-44cc-b990-4df9acdea261",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found existing installation: peft 0.8.2\n",
      "Uninstalling peft-0.8.2:\n",
      "  Successfully uninstalled peft-0.8.2\n",
      "Found existing installation: transformers 4.36.2\n",
      "Uninstalling transformers-4.36.2:\n",
      "  Successfully uninstalled transformers-4.36.2\n",
      "Files removed: 12 (8.6 MB)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import os\n",
    "\n",
    "# Force uninstall PEFT and Transformers\n",
    "os.system(\"pip uninstall -y peft transformers\")\n",
    "\n",
    "# Clean cache\n",
    "os.system(\"pip cache purge\")\n",
    "\n",
    "# Remove lingering folders manually\n",
    "os.system('rm -rf ~/.local/lib/python3.9/site-packages/peft*')\n",
    "os.system('rm -rf ~/.local/lib/python3.9/site-packages/transformers*')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "ed16eca3-3301-49ac-b4d7-8fa38e7a9644",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "256"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "os.system('ls ~/.local/lib/python3.9/site-packages/ | grep peft')\n",
    "os.system('ls ~/.local/lib/python3.9/site-packages/ | grep transformers')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "1b00ed36-991e-4036-8d33-66e3d9c0f8da",
   "metadata": {},
   "outputs": [],
   "source": [
    "# os.system(\"pip install transformers==4.36.2 peft==0.8.2\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "2c01d446-48f3-4deb-a2a1-bcad5ac5d514",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/nfs/home/vlr3588/.local/lib/python3.9/site-packages/transformers/utils/generic.py:441: UserWarning: torch.utils._pytree._register_pytree_node is deprecated. Please use torch.utils._pytree.register_pytree_node instead.\n",
      "  _torch_pytree._register_pytree_node(\n",
      "/nfs/home/vlr3588/.local/lib/python3.9/site-packages/transformers/utils/generic.py:309: UserWarning: torch.utils._pytree._register_pytree_node is deprecated. Please use torch.utils._pytree.register_pytree_node instead.\n",
      "  _torch_pytree._register_pytree_node(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4.36.2\n",
      "0.8.2\n"
     ]
    }
   ],
   "source": [
    "import transformers\n",
    "import peft\n",
    "\n",
    "print(transformers.__version__)  # should be 4.36.2\n",
    "print(peft.__version__)          # should be 0.8.2\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "db5ab5c9-3944-4b67-bfdb-e1c281c27ee8",
   "metadata": {},
   "source": [
    "### Apply LoRA with PEFT"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "7dbfedca-ee13-49bc-a640-72190c729db0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "trainable params: 589,824 || all params: 61,096,448 || trainable%: 0.9653981848502878\n"
     ]
    }
   ],
   "source": [
    "from peft import LoraConfig, get_peft_model\n",
    "from transformers import AutoModelForSeq2SeqLM\n",
    "\n",
    "model = AutoModelForSeq2SeqLM.from_pretrained(\"t5-small\")\n",
    "\n",
    "peft_config = LoraConfig(\n",
    "    r=8,\n",
    "    lora_alpha=32,\n",
    "    target_modules=[\"q\", \"v\", \"k\", \"o\"],\n",
    "    lora_dropout=0.1,\n",
    "    bias=\"none\",\n",
    "    task_type=\"SEQ_2_SEQ_LM\",\n",
    ")\n",
    "\n",
    "model = get_peft_model(model, peft_config)\n",
    "model.print_trainable_parameters()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "86aedbea-23a7-414d-b29c-0c67f465b408",
   "metadata": {},
   "source": [
    "### Train the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "a42e6cef-ff83-40b7-9aa8-6e4b97dbe55e",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "You're using a T5TokenizerFast tokenizer. Please note that with a fast tokenizer, using the `__call__` method is faster than using a method to encode the text followed by a call to the `pad` method to get a padded encoding.\n",
      "/nfs/home/vlr3588/.local/lib/python3.9/site-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n",
      "  warnings.warn('Was asked to gather along dimension 0, but all '\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='3714' max='3714' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [3714/3714 52:22, Epoch 3/3]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>50</td>\n",
       "      <td>2.454000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>100</td>\n",
       "      <td>0.281400</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>150</td>\n",
       "      <td>0.218100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>200</td>\n",
       "      <td>0.187100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>250</td>\n",
       "      <td>0.164800</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>300</td>\n",
       "      <td>0.150400</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>350</td>\n",
       "      <td>0.143600</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>400</td>\n",
       "      <td>0.155100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>450</td>\n",
       "      <td>0.147100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>500</td>\n",
       "      <td>0.147400</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>550</td>\n",
       "      <td>0.143100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>600</td>\n",
       "      <td>0.148700</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>650</td>\n",
       "      <td>0.121900</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>700</td>\n",
       "      <td>0.128000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>750</td>\n",
       "      <td>0.129600</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>800</td>\n",
       "      <td>0.122700</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>850</td>\n",
       "      <td>0.129600</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>900</td>\n",
       "      <td>0.127200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>950</td>\n",
       "      <td>0.128500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1000</td>\n",
       "      <td>0.123900</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1050</td>\n",
       "      <td>0.119800</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1100</td>\n",
       "      <td>0.131400</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1150</td>\n",
       "      <td>0.117800</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1200</td>\n",
       "      <td>0.129300</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1250</td>\n",
       "      <td>0.123400</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1300</td>\n",
       "      <td>0.116500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1350</td>\n",
       "      <td>0.115300</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1400</td>\n",
       "      <td>0.092800</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1450</td>\n",
       "      <td>0.111300</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1500</td>\n",
       "      <td>0.118400</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1550</td>\n",
       "      <td>0.129200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1600</td>\n",
       "      <td>0.108000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1650</td>\n",
       "      <td>0.103000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1700</td>\n",
       "      <td>0.115800</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1750</td>\n",
       "      <td>0.111600</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1800</td>\n",
       "      <td>0.109700</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1850</td>\n",
       "      <td>0.116800</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1900</td>\n",
       "      <td>0.110000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1950</td>\n",
       "      <td>0.105000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2000</td>\n",
       "      <td>0.105900</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2050</td>\n",
       "      <td>0.101800</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2100</td>\n",
       "      <td>0.104700</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2150</td>\n",
       "      <td>0.108400</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2200</td>\n",
       "      <td>0.116700</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2250</td>\n",
       "      <td>0.107100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2300</td>\n",
       "      <td>0.117000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2350</td>\n",
       "      <td>0.110800</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2400</td>\n",
       "      <td>0.108300</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2450</td>\n",
       "      <td>0.104600</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2500</td>\n",
       "      <td>0.109600</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2550</td>\n",
       "      <td>0.111900</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2600</td>\n",
       "      <td>0.100200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2650</td>\n",
       "      <td>0.112300</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2700</td>\n",
       "      <td>0.099100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2750</td>\n",
       "      <td>0.101500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2800</td>\n",
       "      <td>0.100100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2850</td>\n",
       "      <td>0.102200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2900</td>\n",
       "      <td>0.095400</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2950</td>\n",
       "      <td>0.092600</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3000</td>\n",
       "      <td>0.103500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3050</td>\n",
       "      <td>0.095500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3100</td>\n",
       "      <td>0.101200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3150</td>\n",
       "      <td>0.103200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3200</td>\n",
       "      <td>0.103500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3250</td>\n",
       "      <td>0.122700</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3300</td>\n",
       "      <td>0.101000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3350</td>\n",
       "      <td>0.100800</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3400</td>\n",
       "      <td>0.102300</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3450</td>\n",
       "      <td>0.095600</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3500</td>\n",
       "      <td>0.096200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3550</td>\n",
       "      <td>0.098900</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3600</td>\n",
       "      <td>0.102500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3650</td>\n",
       "      <td>0.084300</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3700</td>\n",
       "      <td>0.099300</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/nfs/home/vlr3588/.local/lib/python3.9/site-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n",
      "  warnings.warn('Was asked to gather along dimension 0, but all '\n",
      "/nfs/home/vlr3588/.local/lib/python3.9/site-packages/huggingface_hub/file_download.py:797: FutureWarning: `resume_download` is deprecated and will be removed in version 1.0.0. Downloads always resume when possible. If you want to force a new download, use `force_download=True`.\n",
      "  warnings.warn(\n",
      "/nfs/home/vlr3588/.local/lib/python3.9/site-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n",
      "  warnings.warn('Was asked to gather along dimension 0, but all '\n",
      "/nfs/home/vlr3588/.local/lib/python3.9/site-packages/huggingface_hub/file_download.py:797: FutureWarning: `resume_download` is deprecated and will be removed in version 1.0.0. Downloads always resume when possible. If you want to force a new download, use `force_download=True`.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "TrainOutput(global_step=3714, training_loss=0.1506210140599059, metrics={'train_runtime': 3147.1893, 'train_samples_per_second': 47.192, 'train_steps_per_second': 1.18, 'total_flos': 1.01851053686784e+16, 'train_loss': 0.1506210140599059, 'epoch': 3.0})"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from transformers import Seq2SeqTrainer, Seq2SeqTrainingArguments, DataCollatorForSeq2Seq\n",
    "\n",
    "training_args = Seq2SeqTrainingArguments(\n",
    "    output_dir=\"./lora-t5-small-sentiment\",\n",
    "    per_device_train_batch_size=8,\n",
    "    num_train_epochs=3,\n",
    "    learning_rate=5e-4,\n",
    "    logging_steps=50,\n",
    "    save_strategy=\"epoch\",\n",
    "    fp16=True,\n",
    "    report_to=\"none\",\n",
    ")\n",
    "\n",
    "trainer = Seq2SeqTrainer(\n",
    "    model=model,\n",
    "    args=training_args,\n",
    "    train_dataset=tokenized_dataset,\n",
    "    tokenizer=tokenizer,\n",
    "    data_collator=DataCollatorForSeq2Seq(tokenizer),\n",
    ")\n",
    "\n",
    "trainer.train()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b2664b1f-f3da-4e3a-a2ed-b4736b0479ec",
   "metadata": {},
   "source": [
    "### Save your fine-tuned model:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "d10defc5-e4c8-4c40-9fd8-9fdfdd7c9717",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/nfs/home/vlr3588/.local/lib/python3.9/site-packages/huggingface_hub/file_download.py:797: FutureWarning: `resume_download` is deprecated and will be removed in version 1.0.0. Downloads always resume when possible. If you want to force a new download, use `force_download=True`.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "('./lora-t5-small-sentiment/tokenizer_config.json',\n",
       " './lora-t5-small-sentiment/special_tokens_map.json',\n",
       " './lora-t5-small-sentiment/tokenizer.json')"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.save_pretrained(\"./lora-t5-small-sentiment\")\n",
    "tokenizer.save_pretrained(\"./lora-t5-small-sentiment\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3c343ac0-5aa3-4f07-a02e-c6d99650fd10",
   "metadata": {},
   "source": [
    "### Evaluate the fine-tuned model:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "d0e2a027-dbb0-4509-8db0-320376c7aee5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Question: What is the sentiment of this review? 'I use this with the Nudestix “Citrus Clean Balm & Make-Up Melt“ to double cleanse and it has completely changed my skin (for the better). The make-up melt is oil based and removes all of your makeup super easily. I follow-up with this water based cleanser, and I also use this just by itself when I’m not wearing make-up. It leaves the skin gently cleansed, but without stripping the skin. 10/10 recommend combining with the make-up melt. It’s perfection!'\n",
      "True Sentiment: Positive\n",
      "Fine-tuned Model Answer: Positive\n",
      "\n",
      "Question: What is the sentiment of this review? 'I bought this lip mask after reading the reviews and the hype. Unfortunately, it did not meet my expectations as vaseline petroleum jelly works way better for me.'\n",
      "True Sentiment: Negative\n",
      "Fine-tuned Model Answer: Negative\n",
      "\n",
      "Question: What is the sentiment of this review? 'My review title says it all! I get so excited to get into bed and apply this lip mask. I do see a difference because I suffer from dry cracked lips. I drink a lot of water and apply lip balm daily but nothing helped until I started using this. untiluntistafted usinf this.'\n",
      "True Sentiment: Positive\n",
      "Fine-tuned Model Answer: Positive\n",
      "\n",
      "Question: What is the sentiment of this review? 'I’ve always loved this formula for a long time. I honestly don’t even use it for night time. I use it as an everyday lip balm. I love the texture. Gummy Bear is my second most favourite scent. Grapefruit is the best in my opinion.'\n",
      "True Sentiment: Positive\n",
      "Fine-tuned Model Answer: Positive\n",
      "\n",
      "Question: What is the sentiment of this review? 'If you have dry cracked lips, this is a must have. After a few weeks of use I have learned I will always have by my bedside. I thought it was a little expensive but a little goes a long way. It is worth the price.'\n",
      "True Sentiment: Positive\n",
      "Fine-tuned Model Answer: Positive\n",
      "\n",
      "Question: What is the sentiment of this review? 'The scent isn’t my favourite but it works great! I put it on every night before I go to sleep and every morning I wake up with smooth, moisturizer and soft. Packaging is amazing as well'\n",
      "True Sentiment: Positive\n",
      "Fine-tuned Model Answer: Positive\n",
      "\n",
      "Question: What is the sentiment of this review? 'I’ll give this 2 stars for nice packaging and lovely scent. Upon initial application, it feels very nice. But as I continued to use it I noticed I was getting more and more blackheads/clogged pores and pimples around my lips. I thought it was my Aquaphor but it’s THIS!!!! It also makes my lips even more dry than they initially were. Disappointing:( around my'\n",
      "True Sentiment: Negative\n",
      "Fine-tuned Model Answer: Negative\n",
      "\n",
      "Question: What is the sentiment of this review? 'I use this at night or while I’m putting makeup on. Love the way I don’t have to reapply it during the night. Definitely a win.'\n",
      "True Sentiment: Positive\n",
      "Fine-tuned Model Answer: Positive\n",
      "\n",
      "Question: What is the sentiment of this review? 'I love this stuff. I first had the sample size from a Sephora Birthday gift, and once I had run through it I knew it was a purchase. I live in an incredibly dry environment, great for macarons, but terrible for my skin. This lip mask helps to keep my lips from becoming too chapped.'\n",
      "True Sentiment: Positive\n",
      "Fine-tuned Model Answer: Positive\n",
      "\n",
      "Question: What is the sentiment of this review? 'I purchased the Sweet Candy scent at my local Sephora and I am OBSESSED!! I will be honest, the scent is a bit strong - but they’re all strongly scented. My lips are so soft. 10/10!'\n",
      "True Sentiment: Positive\n",
      "Fine-tuned Model Answer: Positive\n",
      "\n",
      "Question: What is the sentiment of this review? 'this product is a bit pricey but after using one scoop i figured this will take a LONG time to use up the whole container. it smells so good and the container is so cute.'\n",
      "True Sentiment: Positive\n",
      "Fine-tuned Model Answer: Positive\n",
      "\n",
      "Question: What is the sentiment of this review? 'I use this every night and morning and it works wonders! This never fails to make my lips super hydrated! The tint and shine to it makes it even a great lip gloss during the day!'\n",
      "True Sentiment: Positive\n",
      "Fine-tuned Model Answer: Positive\n",
      "\n",
      "Question: What is the sentiment of this review? 'A little goes a long way. Love the fragrance and works great as a night lip mask. Only reason I gave it 4 stars is because of the price.'\n",
      "True Sentiment: Positive\n",
      "Fine-tuned Model Answer: Positive\n",
      "\n",
      "Question: What is the sentiment of this review? 'Honestly I was so excited when I got this in the mail. But unfortunately it is not worth the hype :( I have boughten two of these full size and I went through them so quickly. The ingredients are not very clean and this product made my lips so dry. I wanted to like this product so bad as it’s so cute and smells nice. But unfortunately it is a hard pass for me. I will be sticking to my vaseline and aquaphor for now :/'\n",
      "True Sentiment: Negative\n",
      "Fine-tuned Model Answer: Negative\n",
      "\n",
      "Question: What is the sentiment of this review? 'Does the gummy bear mask smell absolutely delicious?! Yes. Does it do much for my lips overnight? Nope. They are dry and a little chapped in the morning. I honestly have better luck with my vaseline lip therapy but I am still keeping the Laneige to use as a daily balm.'\n",
      "True Sentiment: Neutral\n",
      "Fine-tuned Model Answer: Positive\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from transformers import pipeline, AutoModelForSeq2SeqLM, AutoTokenizer\n",
    "\n",
    "model = AutoModelForSeq2SeqLM.from_pretrained(\"./lora-t5-small-sentiment\")\n",
    "tokenizer = AutoTokenizer.from_pretrained(\"./lora-t5-small-sentiment\")\n",
    "qa_pipeline = pipeline(\"text2text-generation\", model=model, tokenizer=tokenizer)\n",
    "\n",
    "for sample in test_questions:\n",
    "    question = sample[\"question\"]\n",
    "    true_answer = sample[\"answer\"]\n",
    "\n",
    "    response = qa_pipeline(question, max_length=10)[0]['generated_text']\n",
    "\n",
    "    print(f\"Question: {question}\")\n",
    "    print(f\"True Sentiment: {true_answer}\")\n",
    "    print(f\"Fine-tuned Model Answer: {response}\\n\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "42e31dd1-ccd5-4604-ad33-90ce960faad9",
   "metadata": {},
   "source": [
    "## Conclusion\n",
    "\n",
    "- In this assignment, I worked on sentiment classification using Sephora reviews, focusing on predicting Positive, Negative, and Neutral sentiments.\n",
    "- I first evaluated the base T5-small model, which struggled to provide meaningful predictions. To improve performance, I applied LoRA fine-tuning with PEFT, which gave noticeably better results, especially for Positive and Negative sentiments.\n",
    "- However, the model still struggled with Neutral sentiment prediction due to the class imbalance in the dataset, where Neutral examples are underrepresented.\n",
    "- Since LoRA fine-tunes only a small subset of the model's parameters, it is more sensitive to the quality and balance of the training data. Without enough Neutral examples, the model couldn't learn to predict them well.\n",
    "\n",
    "## Future Work\n",
    "- Balance the dataset to include sufficient Neutral examples and re-run LoRA fine-tuning to check if Neutral predictions improve.\n",
    "- Try other techniques like class-weighted loss functions or data augmentation to handle the imbalance.\n",
    "- Explore more advanced fine-tuning strategies to further boost performance across all sentiment classes.\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "51657cde-9c64-49dd-b5c4-16f9a140071b",
   "metadata": {},
   "source": [
    "## UnitTest"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "15ec0cd0-61f2-4d47-9de0-26932d6b0b59",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "298b609c06bd409e8ee3b893dac1f95a",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/2 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='1' max='1' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [1/1 00:00, Epoch 1/1]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Unit test complete!\n"
     ]
    }
   ],
   "source": [
    "import json\n",
    "from datasets import Dataset\n",
    "from transformers import AutoTokenizer, AutoModelForSeq2SeqLM, Seq2SeqTrainer, Seq2SeqTrainingArguments\n",
    "from peft import LoraConfig, get_peft_model\n",
    "\n",
    "# Tiny dataset\n",
    "test_data = [\n",
    "    {\"question\": \"What is the sentiment of this review? 'It works well.'\", \"answer\": \"Positive\"},\n",
    "    {\"question\": \"What is the sentiment of this review? 'It is okay.'\", \"answer\": \"Neutral\"},\n",
    "]\n",
    "\n",
    "dataset = Dataset.from_list(test_data)\n",
    "tokenizer = AutoTokenizer.from_pretrained(\"t5-small\")\n",
    "\n",
    "def tokenize(example):\n",
    "    inputs = tokenizer(example[\"question\"], max_length=128, padding=\"max_length\", truncation=True)\n",
    "    labels = tokenizer(example[\"answer\"], max_length=5, padding=\"max_length\", truncation=True)\n",
    "    labels[\"input_ids\"] = [(id if id != tokenizer.pad_token_id else -100) for id in labels[\"input_ids\"]]\n",
    "    inputs[\"labels\"] = labels[\"input_ids\"]\n",
    "    return inputs\n",
    "\n",
    "tokenized_dataset = dataset.map(tokenize)\n",
    "\n",
    "model = AutoModelForSeq2SeqLM.from_pretrained(\"t5-small\")\n",
    "lora_config = LoraConfig(\n",
    "    r=4, lora_alpha=16, target_modules=[\"q\", \"v\", \"k\", \"o\"],\n",
    "    lora_dropout=0.1, bias=\"none\", task_type=\"SEQ_2_SEQ_LM\",\n",
    ")\n",
    "model = get_peft_model(model, lora_config)\n",
    "\n",
    "training_args = Seq2SeqTrainingArguments(\n",
    "    output_dir=\"./unit_test_output\",\n",
    "    per_device_train_batch_size=2,\n",
    "    num_train_epochs=1,\n",
    "    learning_rate=1e-4,\n",
    "    logging_dir=\"./unit_test_logs\",\n",
    ")\n",
    "\n",
    "trainer = Seq2SeqTrainer(\n",
    "    model=model,\n",
    "    args=training_args,\n",
    "    train_dataset=tokenized_dataset,\n",
    ")\n",
    "\n",
    "trainer.train()\n",
    "print(\"Unit test complete!\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2eb90bc9-111a-470f-90fd-1b0b4c04a950",
   "metadata": {},
   "source": [
    "## Compare Base vs. Fine-Tuned Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "e6273ea6-9e4d-4156-8490-9206f4eca12f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Question: What is the sentiment of this review? 'I use this with the Nudestix “Citrus Clean Balm & Make-Up Melt“ to double cleanse and it has completely changed my skin (for the better). The make-up melt is oil based and removes all of your makeup super easily. I follow-up with this water based cleanser, and I also use this just by itself when I’m not wearing make-up. It leaves the skin gently cleansed, but without stripping the skin. 10/10 recommend combining with the make-up melt. It’s perfection!'\n",
      "True Sentiment: Positive\n",
      "Base Model Answer: this review.! this review\n",
      "Fine-tuned Model Answer: Positive\n",
      "\n",
      "Question: What is the sentiment of this review? 'I bought this lip mask after reading the reviews and the hype. Unfortunately, it did not meet my expectations as vaseline petroleum jelly works way better for me.'\n",
      "True Sentiment: Negative\n",
      "Base Model Answer: this review??? What\n",
      "Fine-tuned Model Answer: Negative\n",
      "\n",
      "Question: What is the sentiment of this review? 'My review title says it all! I get so excited to get into bed and apply this lip mask. I do see a difference because I suffer from dry cracked lips. I drink a lot of water and apply lip balm daily but nothing helped until I started using this. untiluntistafted usinf this.'\n",
      "True Sentiment: Positive\n",
      "Base Model Answer: this review?? this review\n",
      "Fine-tuned Model Answer: Positive\n",
      "\n",
      "Question: What is the sentiment of this review? 'I’ve always loved this formula for a long time. I honestly don’t even use it for night time. I use it as an everyday lip balm. I love the texture. Gummy Bear is my second most favourite scent. Grapefruit is the best in my opinion.'\n",
      "True Sentiment: Positive\n",
      "Base Model Answer: this review?? this formula\n",
      "Fine-tuned Model Answer: Positive\n",
      "\n",
      "Question: What is the sentiment of this review? 'If you have dry cracked lips, this is a must have. After a few weeks of use I have learned I will always have by my bedside. I thought it was a little expensive but a little goes a long way. It is worth the price.'\n",
      "True Sentiment: Positive\n",
      "Base Model Answer: this review?? a\n",
      "Fine-tuned Model Answer: Positive\n",
      "\n",
      "Question: What is the sentiment of this review? 'The scent isn’t my favourite but it works great! I put it on every night before I go to sleep and every morning I wake up with smooth, moisturizer and soft. Packaging is amazing as well'\n",
      "True Sentiment: Positive\n",
      "Base Model Answer: ????\n",
      "Fine-tuned Model Answer: Positive\n",
      "\n",
      "Question: What is the sentiment of this review? 'I’ll give this 2 stars for nice packaging and lovely scent. Upon initial application, it feels very nice. But as I continued to use it I noticed I was getting more and more blackheads/clogged pores and pimples around my lips. I thought it was my Aquaphor but it’s THIS!!!! It also makes my lips even more dry than they initially were. Disappointing:( around my'\n",
      "True Sentiment: Negative\n",
      "Base Model Answer: this review? this review?\n",
      "Fine-tuned Model Answer: Negative\n",
      "\n",
      "Question: What is the sentiment of this review? 'I use this at night or while I’m putting makeup on. Love the way I don’t have to reapply it during the night. Definitely a win.'\n",
      "True Sentiment: Positive\n",
      "Base Model Answer: this review?? the way\n",
      "Fine-tuned Model Answer: Positive\n",
      "\n",
      "Question: What is the sentiment of this review? 'I love this stuff. I first had the sample size from a Sephora Birthday gift, and once I had run through it I knew it was a purchase. I live in an incredibly dry environment, great for macarons, but terrible for my skin. This lip mask helps to keep my lips from becoming too chapped.'\n",
      "True Sentiment: Positive\n",
      "Base Model Answer: this review? of this review?\n",
      "Fine-tuned Model Answer: Positive\n",
      "\n",
      "Question: What is the sentiment of this review? 'I purchased the Sweet Candy scent at my local Sephora and I am OBSESSED!! I will be honest, the scent is a bit strong - but they’re all strongly scented. My lips are so soft. 10/10!'\n",
      "True Sentiment: Positive\n",
      "Base Model Answer: this review?? this review\n",
      "Fine-tuned Model Answer: Positive\n",
      "\n",
      "Question: What is the sentiment of this review? 'this product is a bit pricey but after using one scoop i figured this will take a LONG time to use up the whole container. it smells so good and the container is so cute.'\n",
      "True Sentiment: Positive\n",
      "Base Model Answer: this review?? the review\n",
      "Fine-tuned Model Answer: Positive\n",
      "\n",
      "Question: What is the sentiment of this review? 'I use this every night and morning and it works wonders! This never fails to make my lips super hydrated! The tint and shine to it makes it even a great lip gloss during the day!'\n",
      "True Sentiment: Positive\n",
      "Base Model Answer: this review?? this review\n",
      "Fine-tuned Model Answer: Positive\n",
      "\n",
      "Question: What is the sentiment of this review? 'A little goes a long way. Love the fragrance and works great as a night lip mask. Only reason I gave it 4 stars is because of the price.'\n",
      "True Sentiment: Positive\n",
      "Base Model Answer: this review?? this review\n",
      "Fine-tuned Model Answer: Positive\n",
      "\n",
      "Question: What is the sentiment of this review? 'Honestly I was so excited when I got this in the mail. But unfortunately it is not worth the hype :( I have boughten two of these full size and I went through them so quickly. The ingredients are not very clean and this product made my lips so dry. I wanted to like this product so bad as it’s so cute and smells nice. But unfortunately it is a hard pass for me. I will be sticking to my vaseline and aquaphor for now :/'\n",
      "True Sentiment: Negative\n",
      "Base Model Answer: I was so excited when I got this\n",
      "Fine-tuned Model Answer: Negative\n",
      "\n",
      "Question: What is the sentiment of this review? 'Does the gummy bear mask smell absolutely delicious?! Yes. Does it do much for my lips overnight? Nope. They are dry and a little chapped in the morning. I honestly have better luck with my vaseline lip therapy but I am still keeping the Laneige to use as a daily balm.'\n",
      "True Sentiment: Neutral\n",
      "Base Model Answer: this review?? the Lane\n",
      "Fine-tuned Model Answer: Positive\n",
      "\n"
     ]
    }
   ],
   "source": [
    "import json\n",
    "from transformers import pipeline, AutoTokenizer, AutoModelForSeq2SeqLM\n",
    "\n",
    "# Load test questions\n",
    "with open(\"test_questions.json\", \"r\") as f:\n",
    "    test_questions = json.load(f)\n",
    "\n",
    "# Load base model and tokenizer\n",
    "base_model_name = \"t5-small\"\n",
    "base_tokenizer = AutoTokenizer.from_pretrained(base_model_name)\n",
    "base_model = AutoModelForSeq2SeqLM.from_pretrained(base_model_name)\n",
    "base_pipeline = pipeline(\"text2text-generation\", model=base_model, tokenizer=base_tokenizer)\n",
    "\n",
    "# Load fine-tuned model and tokenizer\n",
    "finetuned_model_path = \"./lora-t5-small-sentiment\"\n",
    "finetuned_tokenizer = AutoTokenizer.from_pretrained(finetuned_model_path)\n",
    "finetuned_model = AutoModelForSeq2SeqLM.from_pretrained(finetuned_model_path)\n",
    "finetuned_pipeline = pipeline(\"text2text-generation\", model=finetuned_model, tokenizer=finetuned_tokenizer)\n",
    "\n",
    "# Compare outputs\n",
    "for sample in test_questions:\n",
    "    question = sample[\"question\"]\n",
    "    true_answer = sample[\"answer\"]\n",
    "\n",
    "    base_response = base_pipeline(question, max_length=10)[0]['generated_text']\n",
    "    finetuned_response = finetuned_pipeline(question, max_length=10)[0]['generated_text']\n",
    "\n",
    "    print(f\"Question: {question}\")\n",
    "    print(f\"True Sentiment: {true_answer}\")\n",
    "    print(f\"Base Model Answer: {base_response}\")\n",
    "    print(f\"Fine-tuned Model Answer: {finetuned_response}\\n\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "497ded10-cdb0-4067-bb2b-8af158eae414",
   "metadata": {},
   "source": [
    " ## Testing generalization by using new, unseen reviews that are not part of your training or test sets. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "93501023-03b4-48b7-8db7-c56f66173f52",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "--- Generalization Test on New, Unseen Reviews ---\n",
      "\n",
      "Review: The product is okay, not bad but nothing special. I wouldn't repurchase.\n",
      "Predicted Sentiment: Negative\n",
      "\n",
      "Review: Terrible experience! It caused a rash after just one use.\n",
      "Predicted Sentiment: Negative\n",
      "\n",
      "Review: Wow! This exceeded my expectations. Smooth application and amazing scent.\n",
      "Predicted Sentiment: Positive\n",
      "\n",
      "Review: It's decent, but I found it a bit overpriced for the results.\n",
      "Predicted Sentiment: Neutral\n",
      "\n",
      "Review: I expected more. It's fine, but didn't really do what it promised.\n",
      "Predicted Sentiment: Negative\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Example of new, unseen reviews for generalization testing\n",
    "new_reviews = [\n",
    "    \"The product is okay, not bad but nothing special. I wouldn't repurchase.\",\n",
    "    \"Terrible experience! It caused a rash after just one use.\",\n",
    "    \"Wow! This exceeded my expectations. Smooth application and amazing scent.\",\n",
    "    \"It's decent, but I found it a bit overpriced for the results.\",\n",
    "    \"I expected more. It's fine, but didn't really do what it promised.\"\n",
    "]\n",
    "\n",
    "print(\"\\n--- Generalization Test on New, Unseen Reviews ---\\n\")\n",
    "for review in new_reviews:\n",
    "    question = f\"What is the sentiment of this review? '{review}'\"\n",
    "    response = qa_pipeline(question, max_length=10)[0]['generated_text']\n",
    "    print(f\"Review: {review}\")\n",
    "    print(f\"Predicted Sentiment: {response}\\n\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "49479bf7-b8ab-4af9-8eee-4dcec3e4870a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "--- Generalization Test on New, Unseen Reviews ---\n",
      "\n",
      "Review: The product is okay, not bad but nothing special. I wouldn't repurchase.\n",
      "True Sentiment: Neutral\n",
      "Predicted Sentiment: Negative\n",
      "\n",
      "Review: Terrible experience! It caused a rash after just one use.\n",
      "True Sentiment: Negative\n",
      "Predicted Sentiment: Negative\n",
      "\n",
      "Review: Wow! This exceeded my expectations. Smooth application and amazing scent.\n",
      "True Sentiment: Positive\n",
      "Predicted Sentiment: Positive\n",
      "\n",
      "Review: It's decent, but I found it a bit overpriced for the results.\n",
      "True Sentiment: Neutral\n",
      "Predicted Sentiment: Neutral\n",
      "\n",
      "Review: I expected more. It's fine, but didn't really do what it promised.\n",
      "True Sentiment: Neutral\n",
      "Predicted Sentiment: Negative\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# New, unseen reviews with their true (expected) sentiments\n",
    "new_reviews = [\n",
    "    {\"review\": \"The product is okay, not bad but nothing special. I wouldn't repurchase.\", \"true_sentiment\": \"Neutral\"},\n",
    "    {\"review\": \"Terrible experience! It caused a rash after just one use.\", \"true_sentiment\": \"Negative\"},\n",
    "    {\"review\": \"Wow! This exceeded my expectations. Smooth application and amazing scent.\", \"true_sentiment\": \"Positive\"},\n",
    "    {\"review\": \"It's decent, but I found it a bit overpriced for the results.\", \"true_sentiment\": \"Neutral\"},\n",
    "    {\"review\": \"I expected more. It's fine, but didn't really do what it promised.\", \"true_sentiment\": \"Neutral\"}\n",
    "]\n",
    "\n",
    "print(\"\\n--- Generalization Test on New, Unseen Reviews ---\\n\")\n",
    "for sample in new_reviews:\n",
    "    review = sample[\"review\"]\n",
    "    true_sentiment = sample[\"true_sentiment\"]\n",
    "\n",
    "    question = f\"What is the sentiment of this review? '{review}'\"\n",
    "    response = qa_pipeline(question, max_length=10)[0]['generated_text']\n",
    "\n",
    "    print(f\"Review: {review}\")\n",
    "    print(f\"True Sentiment: {true_sentiment}\")\n",
    "    print(f\"Predicted Sentiment: {response}\\n\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "ddd4aea4-ab23-4bc8-980f-ad1342d70991",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "requirements.txt generated!\n"
     ]
    }
   ],
   "source": [
    "required_packages = [\n",
    "    \"torch==2.2.0\",\n",
    "    \"transformers==4.36.2\",\n",
    "    \"peft==0.8.2\",\n",
    "    \"datasets==2.16.1\",\n",
    "    \"accelerate==0.26.1\",\n",
    "    \"safetensors==0.5.3\",\n",
    "    \"numpy==1.24.3\",\n",
    "    \"pandas==2.2.1\",\n",
    "    \"tqdm==4.67.1\",\n",
    "    \"scikit-learn==1.4.1.post1\",\n",
    "    \"kagglehub==0.1.5\"  # Remove if not used\n",
    "]\n",
    "\n",
    "with open(\"requirements.txt\", \"w\") as f:\n",
    "    f.write(\"\\n\".join(required_packages))\n",
    "\n",
    "print(\"requirements.txt generated!\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a14de46a-eab2-4224-ba16-d7c23bdbad6e",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
